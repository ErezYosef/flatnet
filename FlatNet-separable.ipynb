{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.io\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRoot = r'flatnet_separable_pointGrey_transposeInit' # specify the path to the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "tform = transform.SimilarityTransform(rotation=0.00174) #to account for small rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phil=np.zeros((500,256,1))\n",
    "phir=np.zeros((620,256,1))\n",
    "phil=phil.astype('float32')\n",
    "phir=phir.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch,momentum=0.99),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch,momentum=0.99),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "class double_conv2(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv2, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3,stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_ch,momentum=0.99),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch,momentum=0.99),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            double_conv2(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=False):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x1.size()[2] - x2.size()[2]\n",
    "        diffY = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, (diffX // 2, int(diffX / 2),\n",
    "                        diffY // 2, int(diffY / 2)))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatNet(nn.Module):\n",
    "    def __init__(self, n_channels=4):\n",
    "        super(FlatNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 128)\n",
    "        self.down1 = down(128, 256)\n",
    "        self.down2 = down(256, 512)\n",
    "        self.down3 = down(512, 1024)\n",
    "        self.down4 = down(1024, 1024)\n",
    "        self.up1 = up(2048, 512)\n",
    "        self.up2 = up(1024, 256)\n",
    "        self.up3 = up(512, 128)\n",
    "        self.up4 = up(256, 128)\n",
    "        self.outc = outconv(128, 3)\n",
    "        self.PhiL =nn.Parameter(torch.tensor(phil)) \n",
    "        self.PhiR=nn.Parameter(torch.tensor(phir)) \n",
    "        self.bn=nn.BatchNorm2d(4,momentum=0.99)\n",
    "    def forward(self, Xinp):\n",
    "        \n",
    "        X0=F.leaky_relu(torch.matmul(torch.matmul(Xinp[:,0,:,:],self.PhiR[:,:,0]).permute(0,2,1),self.PhiL[:,:,0]).permute(0,2,1).unsqueeze(3))\n",
    "        X11=F.leaky_relu(torch.matmul(torch.matmul(Xinp[:,1,:,:],self.PhiR[:,:,0]).permute(0,2,1),self.PhiL[:,:,0]).permute(0,2,1).unsqueeze(3))\n",
    "        X12=F.leaky_relu(torch.matmul(torch.matmul(Xinp[:,2,:,:],self.PhiR[:,:,0]).permute(0,2,1),self.PhiL[:,:,0]).permute(0,2,1).unsqueeze(3))\n",
    "        X2=F.leaky_relu(torch.matmul(torch.matmul(Xinp[:,3,:,:],self.PhiR[:,:,0]).permute(0,2,1),self.PhiL[:,:,0]).permute(0,2,1).unsqueeze(3))\n",
    "        Xout=torch.cat((X2,X12,X11,X0),3)\n",
    "        x = Xout.permute(0,3,1,2)\n",
    "        x = self.bn(x)\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "\n",
    "            \n",
    "        return torch.sigmoid(x),Xout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatnet = FlatNet(4)\n",
    "flatnet.load_state_dict(torch.load(modelRoot,map_location=torch.device('cpu')))\n",
    "flatnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X):\n",
    "    X=X/65535.0\n",
    "    X_train=np.zeros((1,4,500,620))\n",
    "    im1=np.zeros((512,640,4))\n",
    "    im1[:,:,0]=X[0::2, 0::2]#b\n",
    "    im1[:,:,1]=X[0::2, 1::2]#gb\n",
    "    im1[:,:,2]=X[1::2, 0::2]#gr\n",
    "    im1[:,:,3]=X[1::2, 1::2]#r\n",
    "    im1=transform.warp(im1,tform)\n",
    "    im=im1[6:506,10:630,:]      \n",
    "    rowMeans = im.mean(axis=1, keepdims=True)\n",
    "    colMeans = im.mean(axis=0, keepdims=True)\n",
    "    allMean = rowMeans.mean()\n",
    "    im = im - rowMeans - colMeans + allMean\n",
    "\n",
    "    X_train[0,:,:,:]=np.swapaxes(np.swapaxes(im,0,2),1,2)\n",
    "    X_train=X_train.astype('float32')\n",
    "    X_val=torch.from_numpy(X_train)\n",
    "    Xvalout=flatnet(X_val)\n",
    "    ims=Xvalout.detach().numpy()\n",
    "    ims=np.swapaxes(np.swapaxes(ims[0,:,:,:],0,2),0,1)\n",
    "    ims=(ims-np.min(ims))/(np.max(ims)-np.min(ims))\n",
    "    return ims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=skimage.io.imread(r'set3\\fc_8.png') ## Specify the path to the measurement\n",
    "recn = evaluate(X)\n",
    "skimage.io.imshow(recn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
